{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flight Price Prediction\n",
    "#### Vectorization\n",
    "\n",
    "Lets vectorize the processed data and store our vectorizers in pickle file. After that we will apply various ML models and do cross validation as next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.sparse import hstack\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed = pd.read_csv('../data/processed/processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 300259 entries, 0 to 300258\n",
      "Data columns (total 12 columns):\n",
      " #   Column          Non-Null Count   Dtype \n",
      "---  ------          --------------   ----- \n",
      " 0   airline         300259 non-null  object\n",
      " 1   ch_code         300259 non-null  object\n",
      " 2   num_code        300259 non-null  object\n",
      " 3   from            300259 non-null  object\n",
      " 4   time_taken      300259 non-null  int64 \n",
      " 5   stop            300259 non-null  object\n",
      " 6   to              300259 non-null  object\n",
      " 7   price           300259 non-null  int64 \n",
      " 8   type            300259 non-null  object\n",
      " 9   days_left       300259 non-null  int64 \n",
      " 10  dep_time_phase  300259 non-null  object\n",
      " 11  arr_time_phase  300259 non-null  object\n",
      "dtypes: int64(3), object(9)\n",
      "memory usage: 27.5+ MB\n"
     ]
    }
   ],
   "source": [
    "processed['num_code'] = processed['num_code'].apply(str)\n",
    "processed.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data is vectorized\n",
      "Shape of data after vectorization: (300259, 44)\n"
     ]
    }
   ],
   "source": [
    "categorical_features = ['airline', 'from', 'to', 'type', 'dep_time_phase', 'arr_time_phase']\n",
    "numerical_features = ['days_left']\n",
    "\n",
    "cat_pipeline = Pipeline(steps = [(\"ohe\", OneHotEncoder())])\n",
    "num_pipeline = Pipeline(steps = [(\"imputer\", SimpleImputer(strategy=\"most_frequent\"))])\n",
    "\n",
    "vectorizer = ColumnTransformer([(\"cat_piplines\", cat_pipeline, categorical_features), (\"num_pipeline\", num_pipeline, numerical_features)])\n",
    "\n",
    "vectorized_data = vectorizer.fit_transform(processed)\n",
    "\n",
    "print('Data is vectorized')\n",
    "\n",
    "print('Shape of data after vectorization: {0}'.format(vectorized_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dumped the vectorizer in ../models/vectorizer.pkl file\n"
     ]
    }
   ],
   "source": [
    "vectorizer_file = \"../models/vectorizer.pkl\"\n",
    "with open(vectorizer_file, 'wb') as f:\n",
    "    pickle.dump(vectorizer, f)\n",
    "print('Dumped the vectorizer in {} file'.format(vectorizer_file))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export vectorized data so that we can train our model next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<300259x44 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2702331 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Before that we will add 'price' column\n",
    "vectorized_data_stacked = hstack((vectorized_data, processed['price'].values.reshape(-1,1))).tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorized data exported.\n",
      "List of files under ../data/processed: ['.gitkeep', 'processed.csv', 'vectorized_data.csv']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "processed_data_folder = \"../data/processed\"\n",
    "\n",
    "vectorized_data_arr = vectorized_data_stacked.toarray() \n",
    "np.savetxt(processed_data_folder+\"/vectorized_data.csv\",vectorized_data_arr, fmt='%s', delimiter=',')\n",
    "print('Vectorized data exported.')\n",
    "print('List of files under ../data/processed: {0}'.format(os.listdir(processed_data_folder)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
